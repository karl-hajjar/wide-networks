{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "\n",
    "NOTEBOOK_DIR = os.path.dirname(cwd)\n",
    "ROOT = os.path.dirname(os.path.dirname(os.path.dirname(NOTEBOOK_DIR)))\n",
    "\n",
    "FIGURES_DIR = os.path.join(ROOT, 'figures/abc_parameterizations/training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as pylab\n",
    "\n",
    "from pytorch.job_runners.abc_parameterizations.abc_runner import ABCRunner\n",
    "from pytorch.models.abc_params.fully_connected.ipllr import FcIPLLR\n",
    "from utils.tools import read_yaml\n",
    "from pytorch.configs.model import ModelConfig\n",
    "from torch.utils.data import Dataset, Subset, DataLoader\n",
    "from utils.plot.abc_parameterizations.results import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH = os.path.join(ROOT, 'pytorch/configs/abc_parameterizations')\n",
    "EXPERIMENTS_DIR = 'experiments'\n",
    "MODEL_NAME = 'fc_ipllr'\n",
    "CONFIG_FILE = 'fc_ipllr.yaml'\n",
    "\n",
    "N_TRIALS = 5\n",
    "L = 6  # n_layers - 1\n",
    "WIDTH = 1024\n",
    "N_WARMUP_STEPS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation=\"relu\"\n",
    "n_steps=600 \n",
    "base_lr=0.01\n",
    "batch_size=512\n",
    "dataset=\"mnist\"\n",
    "download=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = '{}_{}'.format(MODEL_NAME, dataset)\n",
    "config_path = os.path.join(CONFIG_PATH, '{}.yaml'.format(model_name))\n",
    "config_dict = read_yaml(config_path)\n",
    "\n",
    "# define corresponding directory in experiments folder\n",
    "base_experiment_path = os.path.join(ROOT, EXPERIMENTS_DIR, model_name)  # base experiment folder\n",
    "\n",
    "# Load data & define models\n",
    "logger = logging.getLogger()\n",
    "logger.info('Loading data ...')\n",
    "if dataset == 'mnist':\n",
    "    from utils.dataset.mnist import load_data\n",
    "elif dataset == 'cifar10':\n",
    "    from utils.dataset.cifar10 import load_data\n",
    "elif dataset == 'cifar100':\n",
    "    # TODO : add cifar100 to utils.dataset\n",
    "    pass\n",
    "else:\n",
    "    error = ValueError(\"dataset must be one of ['mnist', 'cifar10', 'cifar100'] but was {}\".format(dataset))\n",
    "    logger.error(error)\n",
    "    raise error\n",
    "\n",
    "# prepare data\n",
    "training_dataset, test_dataset = load_data(download=download, flatten=True)\n",
    "val_dataset = deepcopy(training_dataset)  # copy train_data into validation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = DataLoader(training_dataset, shuffle=True, batch_size=batch_size)\n",
    "val_data_loader = DataLoader(val_dataset, shuffle=False, batch_size=batch_size)\n",
    "test_data_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict['architecture']['width'] = WIDTH\n",
    "config_dict['architecture']['n_layers'] = L + 1\n",
    "config_dict['optimizer']['params']['lr'] = base_lr\n",
    "config_dict['activation']['name'] = activation\n",
    "config_dict['training']['n_steps'] = n_steps\n",
    "config_dict['training']['batch_size'] = batch_size\n",
    "config_dict['scheduler'] = {'name': 'warmup_switch',\n",
    "                            'params': {'n_warmup_steps': N_WARMUP_STEPS,\n",
    "                                       'calibrate_base_lr': True,\n",
    "                                       'default_calibration': False}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define config and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ModelConfig(config_dict=config_dict)  # define the config as a class to pass to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_calibration_batches = list(train_data_loader)[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FcIPLLR(config, n_warmup_steps=N_WARMUP_STEPS, lr_calibration_batches=lr_calibration_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.01,\n",
       " 15.408360481262207,\n",
       " 36.97975540161133,\n",
       " 38.14841079711914,\n",
       " 40.09565353393555,\n",
       " 44.029083251953125,\n",
       " 9.410510063171387]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.scheduler.initial_base_lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[34359738368.0,\n",
       " 1099511627776.0,\n",
       " 1099511627776.0,\n",
       " 1099511627776.0,\n",
       " 1099511627776.0,\n",
       " 1099511627776.0,\n",
       " 34359738368.0]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.scheduler.current_lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1024, 1048576, 1048576, 1048576, 1048576, 1048576, 1024]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.scheduler.warm_lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[343597383.68,\n",
       " 16941671514112.0,\n",
       " 40659671056384.0,\n",
       " 41944621252608.0,\n",
       " 44085637283840.0,\n",
       " 48410488995840.0,\n",
       " 323342663680.0]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[pg['lr'] for pg in model.optimizer.param_groups]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[343597383.68,\n",
       " 16941671514112.0,\n",
       " 40659671056384.0,\n",
       " 41944621252608.0,\n",
       " 44085637283840.0,\n",
       " 48410488995840.0,\n",
       " 323342663680.0]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[pg['lr'] for pg in model.scheduler.optimizer.param_groups]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1048576"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1024 **2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16941671514112.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1099511627776.0 * 15.408360481262207"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16941671514112.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16941671514112.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
