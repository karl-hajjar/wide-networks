{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f33a5f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "918c35a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0748368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "\n",
    "NOTEBOOK_DIR = os.path.dirname(cwd)\n",
    "ROOT = os.path.dirname(os.path.dirname(os.path.dirname(NOTEBOOK_DIR)))\n",
    "\n",
    "FIGURES_DIR = os.path.join(ROOT, 'figures/abc_parameterizations/training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73eee4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b393b9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as pylab\n",
    "from copy import deepcopy\n",
    "\n",
    "from pytorch.configs.model import ModelConfig\n",
    "from pytorch.models.abc_params.fully_connected.ipllr import FcIPLLR\n",
    "from utils.tools import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf90c27f",
   "metadata": {},
   "source": [
    "## Set variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e137e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 8\n",
    "WIDTH = 1024  # 8000\n",
    "BASE_LR = 1.0\n",
    "N_STEPS = 2\n",
    "BIAS = False\n",
    "ACTIVATION = 'tanh'\n",
    "CONFIG_FILE = 'fc_ipllr_mnist.yaml'\n",
    "\n",
    "DIM = 20\n",
    "OUTPUT_DIM = 1\n",
    "LOSS = 'mse'\n",
    "N_VAL = 100\n",
    "SEED = 42\n",
    "\n",
    "FONTSIZE = 12\n",
    "FIGSIZE = (10, 6)\n",
    "\n",
    "fig_dir = os.path.join(ROOT, FIGURES_DIR, 'linearization')\n",
    "\n",
    "params = {'legend.fontsize': FONTSIZE,\n",
    "         'axes.labelsize': FONTSIZE,\n",
    "         'axes.titlesize': FONTSIZE,\n",
    "         'xtick.labelsize': FONTSIZE,\n",
    "         'ytick.labelsize': FONTSIZE}\n",
    "pylab.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fce2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random_seeds(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbef40b",
   "metadata": {},
   "source": [
    "## Model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5f3612",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.randn(size=(N_STEPS+1, 1, DIM), requires_grad=False)\n",
    "y_train = torch.ones(size=(N_STEPS+1, 1, OUTPUT_DIM), requires_grad=False) / 2\n",
    "\n",
    "x_val = torch.randn(size=(N_STEPS, 1, DIM), requires_grad=False)\n",
    "y_val = torch.ones(size=(N_STEPS, 1, OUTPUT_DIM), requires_grad=False) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4983b141",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict = read_yaml(os.path.join(ROOT, 'pytorch/configs/abc_parameterizations', CONFIG_FILE))\n",
    "config_dict['architecture']['width'] = WIDTH\n",
    "config_dict['architecture']['n_layers'] = L + 1\n",
    "config_dict['architecture']['input_size'] = DIM\n",
    "config_dict['architecture']['output_size'] = OUTPUT_DIM\n",
    "config_dict['optimizer']['params']['lr'] = BASE_LR\n",
    "config_dict['activation']['name'] = ACTIVATION\n",
    "config_dict['loss'] = {'name': 'mse', 'params': {'reduction': 'mean'}}\n",
    "config_dict['scheduler']['params']['calibrate_base_lr'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac0902e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ModelConfig(config_dict=config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469b7b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FcIPLLR(config)\n",
    "pg = list(model.optimizer.param_groups)\n",
    "pg[0]['lr'] = pg[0]['lr'] / DIM\n",
    "#for l in range(2, L):\n",
    "#    pg[l]['lr'] = pg[l]['lr'] * (WIDTH ** 0.5)\n",
    "model_0 = deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebe89c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_backward(x, y):\n",
    "    h_grads = []\n",
    "    x_grads = []\n",
    "\n",
    "    hs = []\n",
    "    xs = []\n",
    "    \n",
    "    model.optimizer.zero_grad()\n",
    "    h = (model.width ** (-model.a[0])) * model.input_layer.forward(x)  # h_0 first layer pre-activations\n",
    "    hs.append(h)\n",
    "\n",
    "    x = model.activation(h)  # x_0, first layer activations\n",
    "    xs.append(x)\n",
    "\n",
    "    for l, layer in enumerate(model.intermediate_layers):  # L-1 intermediate layers\n",
    "        h = (model.width ** (-model.a[l+1])) * layer.forward(x)  # h_l, layer l pre-activations\n",
    "        hs.append(h)\n",
    "        x = model.activation(h)  # x_l, l-th layer activations\n",
    "        xs.append(x)\n",
    "    \n",
    "    for h_ in hs:\n",
    "        h_.retain_grad()\n",
    "    for x_ in xs:\n",
    "        x_.retain_grad()\n",
    "        \n",
    "    y_hat = (model.width ** (-model.a[model.n_layers-1])) * model.output_layer.forward(x)  # f(x)\n",
    "    y_hat.retain_grad()\n",
    "    \n",
    "    loss_ = model.loss(y_hat, y)\n",
    "    loss_.backward()\n",
    "    \n",
    "    h_grads = [h_.grad for h_ in hs]\n",
    "    x_grads = [x_.grad for x_ in xs]\n",
    "    \n",
    "    y_hat_grad = y_hat.grad\n",
    "    \n",
    "    return  hs, xs, y_hat, h_grads, x_grads, y_hat_grad, loss_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f17733",
   "metadata": {},
   "source": [
    "## 1st forward backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094ab80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hs0, xs0, y_hat0, h_grads0, x_grads0, y_hat_grad0, loss_0 = forward_backward(x_train[0, : ,:], y_train[0, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9196ccc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tilde_hs0 = []\n",
    "tilde_xs0 = []\n",
    "tilde_h_grads0 = []\n",
    "tilde_x_grads0 = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for l in range(L):\n",
    "        forward_scale = WIDTH ** (l/2)\n",
    "        tilde_hs0.append(forward_scale * hs0[l])\n",
    "        tilde_xs0.append(forward_scale * xs0[l])\n",
    "        \n",
    "        backward_scale = WIDTH * (WIDTH ** ((L-(l+1)) / 2))\n",
    "        tilde_h_grads0.append(backward_scale * h_grads0[l])\n",
    "        tilde_x_grads0.append(backward_scale * x_grads0[l])\n",
    "        \n",
    "    tilde_y_hat0 = (WIDTH ** (L/2)) * y_hat0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64a406c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for tilde_h in tilde_hs0:\n",
    "        print(torch.sum((tilde_h)**2).detach().item() / WIDTH)\n",
    "    print('')\n",
    "\n",
    "    for tilde_x in tilde_xs0:\n",
    "        print(torch.sum((tilde_x)**2).detach().item() / WIDTH)\n",
    "        \n",
    "    print((tilde_y_hat0.detach().item())**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49df3e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for tilde_h_grad in tilde_h_grads0:\n",
    "        print(torch.sum((tilde_h_grad)**2).detach().item() / WIDTH)\n",
    "    print('')\n",
    "\n",
    "    for tilde_x_grad in tilde_x_grads0:\n",
    "        print(torch.sum((tilde_x_grad)**2).detach().item() / WIDTH)\n",
    "        \n",
    "    print((y_hat_grad0.detach().item())**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc8c125",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for h in hs0:\n",
    "        print(np.sqrt(torch.sum((h)**2).detach().item() / WIDTH))\n",
    "    print('')\n",
    "\n",
    "    for x in xs0:\n",
    "        print(np.sqrt(torch.sum((x)**2).detach().item() / WIDTH))\n",
    "        \n",
    "    print(y_hat0.detach().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd57358",
   "metadata": {},
   "source": [
    "## 1st optimizer step : weight updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9550822c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimizer.step()\n",
    "model.scheduler.step()\n",
    "model_1 = deepcopy(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58b1809",
   "metadata": {},
   "source": [
    "## 2nd forward backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dd3cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "hs1, xs1, y_hat1, h_grads1, x_grads1, y_hat_grad1, loss_1 = forward_backward(x_train[1, : ,:], y_train[1, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d6aefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for h in hs1:\n",
    "        print(np.sqrt(torch.sum((h)**2).detach().item() / WIDTH))\n",
    "    print('')\n",
    "\n",
    "    for x in xs1:\n",
    "        print(np.sqrt(torch.sum((x)**2).detach().item() / WIDTH))\n",
    "        \n",
    "    print(y_hat1.detach().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9224c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for l in range(L):\n",
    "        print(torch.sum(tilde_xs0[l] * xs1[l]).detach().item() / WIDTH)\n",
    "    print(model_0.output_layer(xs1[2]).detach().item() / WIDTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b061bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for l in range(L):\n",
    "        if l == 0:\n",
    "            print(torch.sum(tilde_xs0[l] * xs1[l]).detach().item() / WIDTH)\n",
    "        else:\n",
    "            print(torch.sum(tilde_xs0[l] * xs1[l]).detach().item() / np.sqrt(WIDTH))\n",
    "    print(model_0.output_layer(xs1[2]).detach().item() / np.sqrt(WIDTH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f64876",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    print(torch.sum(tilde_xs0[0] * xs1[0]).detach().item() / WIDTH)\n",
    "    print(torch.sum(tilde_xs0[1] * xs1[1]).detach().item() / np.sqrt(WIDTH))\n",
    "    print(torch.sum(tilde_xs0[2] * xs1[2]).detach().item() / np.sqrt(WIDTH))\n",
    "    \n",
    "    print(model_0.output_layer(xs1[2]).detach().item() / np.sqrt(WIDTH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cb9e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for h_grad in h_grads1:\n",
    "        print(np.sqrt(torch.sum((h_grad)**2).detach().item() / WIDTH))\n",
    "    print('')\n",
    "\n",
    "    for x_grad in x_grads1:\n",
    "        print(np.sqrt(torch.sum((x_grad)**2).detach().item() / WIDTH))\n",
    "        \n",
    "    print(y_hat_grad1.detach().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b36444d",
   "metadata": {},
   "source": [
    "## 2nd optimizer step : weight updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f50ceee",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    print([g['lr'] for g in model.optimizer.param_groups])\n",
    "    #for g in model.optimizer.param_groups:\n",
    "    #    g['lr'] = g['lr'] * 0.0001\n",
    "    #print([g['lr'] for g in model.optimizer.param_groups])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae09096",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimizer.step()\n",
    "model_2 = deepcopy(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f781ccc0",
   "metadata": {},
   "source": [
    "## 3rd forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0081f14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hs2, xs2, y_hat2, h_grads2, x_grads2, y_hat_grad2, loss_2 = forward_backward(x_train[2, : ,:], y_train[2, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c02fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for h in hs2:\n",
    "        print(np.sqrt(torch.sum((h)**2).detach().item() / WIDTH))\n",
    "    print('')\n",
    "\n",
    "    for x in xs2:\n",
    "        print(np.sqrt(torch.sum((x)**2).detach().item() / WIDTH))\n",
    "        \n",
    "    print(y_hat2.detach().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48ebc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for l in range(L):\n",
    "        print(torch.sum(tilde_xs0[l] * xs2[l]).detach().item() / WIDTH)\n",
    "\n",
    "    \n",
    "    print(model_0.output_layer(xs2[2]).detach().item() / WIDTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a76583d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for l in range(L):\n",
    "        print(torch.sum(xs1[l] * xs2[l]).detach().item() / WIDTH)\n",
    "    \n",
    "    print(model_1.output_layer(xs2[2]).detach().item() / WIDTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d434f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
