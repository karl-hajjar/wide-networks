{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "\n",
    "NOTEBOOK_DIR = os.path.dirname(cwd)\n",
    "ROOT = os.path.dirname(os.path.dirname(os.path.dirname(NOTEBOOK_DIR)))\n",
    "\n",
    "FIGURES_DIR = os.path.join(ROOT, 'figures/abc_parameterizations/debug_ipllr_renorm')\n",
    "CONFIG_PATH = os.path.join(ROOT, 'pytorch/configs/abc_parameterizations', 'fc_ipllr_mnist.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, Subset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from utils.tools import read_yaml, set_random_seeds\n",
    "from pytorch.configs.base import BaseConfig\n",
    "from pytorch.configs.model import ModelConfig\n",
    "from pytorch.models.abc_params.fully_connected.ipllr import FcIPLLR\n",
    "from pytorch.models.abc_params.fully_connected.muP import FCmuP\n",
    "from pytorch.models.abc_params.fully_connected.ntk import FCNTK\n",
    "from pytorch.models.abc_params.fully_connected.standard_fc_ip import StandardFCIP\n",
    "from utils.data.mnist import load_data\n",
    "from utils.abc_params.debug_ipllr import *\n",
    "from utils.plot.abc_parameterizations.debug_ipllr import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load basic configuration and define variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRIALS = 5\n",
    "SEED = 30\n",
    "L = 6\n",
    "width = 1024\n",
    "n_warmup_steps = 1\n",
    "batch_size = 512\n",
    "base_lr = 0.1\n",
    "n_steps = 100\n",
    "renorm_first = False\n",
    "scale_first_lr = False\n",
    "\n",
    "set_random_seeds(SEED)  # set random seed for reproducibility\n",
    "config_dict = read_yaml(CONFIG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict = read_yaml(CONFIG_PATH)\n",
    "\n",
    "input_size = config_dict['architecture']['input_size']\n",
    "\n",
    "config_dict['architecture']['width'] = width\n",
    "config_dict['architecture']['n_layers'] = L + 1\n",
    "config_dict['optimizer']['params']['lr'] = base_lr\n",
    "config_dict['scheduler'] = {'name': 'warmup_switch',\n",
    "                            'params': {'n_warmup_steps': n_warmup_steps,\n",
    "                                       'calibrate_base_lr': True,\n",
    "                                       'default_calibration': False}}\n",
    "        \n",
    "base_model_config = ModelConfig(config_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data & define models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset, test_dataset = load_data(download=False, flatten=True)\n",
    "train_data_loader = DataLoader(training_dataset, shuffle=True, batch_size=batch_size)\n",
    "test_batches = list(DataLoader(test_dataset, shuffle=False, batch_size=batch_size))\n",
    "batches = list(train_data_loader)\n",
    "eval_batch = test_batches[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial base lr : [78.5, 38.08141326904297, 68.91138458251953, 68.3167724609375, 74.03038024902344, 102.55865478515625, 30.983808517456055]\n",
      "initial base lr : [78.5, 37.010562896728516, 66.8042984008789, 72.8503189086914, 78.61959075927734, 90.54930877685547, 29.0798397064209]\n",
      "initial base lr : [78.5, 36.512081146240234, 58.382625579833984, 65.4113540649414, 75.37689971923828, 83.77328491210938, 22.76885414123535]\n",
      "initial base lr : [78.5, 42.51643371582031, 72.11700439453125, 76.09538269042969, 83.21681213378906, 115.44151306152344, 35.31344223022461]\n",
      "initial base lr : [78.5, 40.96342086791992, 71.92338562011719, 69.65662384033203, 77.32463836669922, 93.46656036376953, 26.484838485717773]\n",
      "initial base lr : [78.5, 36.689453125, 71.21871948242188, 70.73763275146484, 75.81897735595703, 87.43914794921875, 28.48207664489746]\n",
      "initial base lr : [78.5, 33.913116455078125, 59.712738037109375, 63.80599594116211, 63.03622055053711, 69.04557800292969, 19.315895080566406]\n",
      "initial base lr : [78.5, 35.8175163269043, 68.18766784667969, 61.61366271972656, 69.08861541748047, 74.56391906738281, 21.61155128479004]\n",
      "initial base lr : [78.5, 36.026309967041016, 65.64313507080078, 63.412353515625, 72.14653015136719, 95.60570526123047, 23.616498947143555]\n",
      "initial base lr : [78.5, 41.00617980957031, 72.02057647705078, 75.40982055664062, 77.92902374267578, 99.7586669921875, 29.3252010345459]\n",
      "initial base lr : [78.5, 46.89384460449219, 74.63957977294922, 79.06087493896484, 85.88162994384766, 100.42208862304688, 24.352495193481445]\n",
      "initial base lr : [78.5, 37.21493148803711, 65.64586639404297, 72.34772491455078, 74.59025573730469, 84.32369232177734, 22.181991577148438]\n",
      "initial base lr : [78.5, 36.662113189697266, 70.52474212646484, 71.66820526123047, 81.14805603027344, 104.29150390625, 25.705419540405273]\n",
      "initial base lr : [78.5, 37.94365310668945, 64.76741027832031, 65.78016662597656, 67.94827270507812, 81.2011489868164, 27.014081954956055]\n",
      "initial base lr : [78.5, 34.27191162109375, 59.26192092895508, 59.89235305786133, 67.5495834350586, 78.48600006103516, 23.874181747436523]\n"
     ]
    }
   ],
   "source": [
    "config_dict['scheduler']['params']['calibrate_base_lr'] = False\n",
    "config = ModelConfig(config_dict)\n",
    "\n",
    "ipllrs = [FcIPLLR(config) for _ in range(N_TRIALS)]\n",
    "#ipllrs_renorm = [FcIPLLR(config) for _ in range(N_TRIALS)]\n",
    "#ipllrs_renorm_scale_lr = [FcIPLLR(config) for _ in range(N_TRIALS)]\n",
    "\n",
    "config_dict['scheduler']['params']['calibrate_base_lr'] = True\n",
    "config = ModelConfig(config_dict)\n",
    "ipllrs_calib = [FcIPLLR(config, lr_calibration_batches=batches) for _ in range(N_TRIALS)]\n",
    "ipllrs_calib_renorm = [FcIPLLR(config, lr_calibration_batches=batches) for _ in range(N_TRIALS)]\n",
    "ipllrs_calib_renorm_scale_lr = [FcIPLLR(config, lr_calibration_batches=batches) for _ in range(N_TRIALS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(N_TRIALS):\n",
    "    # copy params\n",
    "    #ipllrs_renorm[i].copy_initial_params_from_model(ipllrs[i])\n",
    "    #ipllrs_renorm_scale_lr[i].copy_initial_params_from_model(ipllrs[i])\n",
    "    \n",
    "    ipllrs_calib[i].copy_initial_params_from_model(ipllrs[i])\n",
    "    ipllrs_calib_renorm[i].copy_initial_params_from_model(ipllrs[i])\n",
    "    ipllrs_calib_renorm_scale_lr[i].copy_initial_params_from_model(ipllrs[i])\n",
    "    \n",
    "    # re-initialize\n",
    "    #ipllrs_renorm[i].initialize_params()\n",
    "    #ipllrs_renorm_scale_lr[i].initialize_params()\n",
    "    \n",
    "    ipllrs_calib[i].initialize_params()\n",
    "    ipllrs_calib_renorm[i].initialize_params()\n",
    "    ipllrs_calib_renorm_scale_lr[i].initialize_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial base lr : [0.1, 0.06003998592495918, 1.2169116735458374, 2.17669939994812, 2.4937546253204346, 2.8725359439849854, 0.8645324110984802]\n",
      "initial base lr : [0.1, 0.0596611388027668, 1.2741634845733643, 2.544586658477783, 2.7952044010162354, 3.329960584640503, 1.0341224670410156]\n",
      "initial base lr : [0.1, 0.059218455106019974, 1.2441296577453613, 2.4515788555145264, 2.6010076999664307, 3.0965986251831055, 0.8844329118728638]\n",
      "initial base lr : [0.1, 0.060484614223241806, 1.2854281663894653, 2.2207565307617188, 2.7277324199676514, 3.3855533599853516, 0.9613930583000183]\n",
      "initial base lr : [0.1, 0.06183946132659912, 1.1814137697219849, 2.329699754714966, 2.2961533069610596, 2.620152473449707, 0.7345650792121887]\n",
      "initial base lr : [78.5, 35.073184967041016, 59.817752838134766, 61.449581146240234, 69.81730651855469, 80.47264099121094, 24.22148323059082]\n",
      "initial base lr : [78.5, 36.027191162109375, 66.83576965332031, 72.37831115722656, 78.34403991699219, 93.29310607910156, 28.972349166870117]\n",
      "initial base lr : [78.5, 36.12922668457031, 66.28324890136719, 69.72453308105469, 72.82794952392578, 86.75300598144531, 24.77837371826172]\n",
      "initial base lr : [78.5, 36.84844207763672, 67.04863739013672, 63.18452072143555, 76.40595245361328, 94.84998321533203, 26.93561363220215]\n",
      "initial base lr : [78.5, 34.1056022644043, 60.1785774230957, 66.5586929321289, 64.38264465332031, 73.41019439697266, 20.58107566833496]\n",
      "initial base lr : [78.5, 35.073184967041016, 59.817752838134766, 61.449581146240234, 69.81730651855469, 80.47264099121094, 24.22148323059082]\n",
      "initial base lr : [78.5, 36.027191162109375, 66.83576965332031, 72.37831115722656, 78.34403991699219, 93.29310607910156, 28.972349166870117]\n",
      "initial base lr : [78.5, 36.12922668457031, 66.28324890136719, 69.72453308105469, 72.82794952392578, 86.75300598144531, 24.77837371826172]\n",
      "initial base lr : [78.5, 36.84844207763672, 67.04863739013672, 63.18452072143555, 76.40595245361328, 94.84998321533203, 26.93561363220215]\n",
      "initial base lr : [78.5, 34.1056022644043, 60.1785774230957, 66.5586929321289, 64.38264465332031, 73.41019439697266, 20.58107566833496]\n"
     ]
    }
   ],
   "source": [
    "# Make sure calibration takes into account normalization\n",
    "\n",
    "for ipllr in ipllrs_calib:    \n",
    "    initial_base_lrs = ipllr.scheduler.calibrate_base_lr(ipllr, batches=batches, normalize_first=False)\n",
    "    ipllr.scheduler._set_param_group_lrs(initial_base_lrs)\n",
    "    \n",
    "for ipllr in ipllrs_calib_renorm:        \n",
    "    initial_base_lrs = ipllr.scheduler.calibrate_base_lr(ipllr, batches=batches, normalize_first=True)\n",
    "    ipllr.scheduler._set_param_group_lrs(initial_base_lrs)\n",
    "    \n",
    "for ipllr in ipllrs_calib_renorm_scale_lr:            \n",
    "    initial_base_lrs = ipllr.scheduler.calibrate_base_lr(ipllr, batches=batches, normalize_first=True)\n",
    "    ipllr.scheduler._set_param_group_lrs(initial_base_lrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale lr of first layer if needed\n",
    "\n",
    "#for ipllr in ipllrs_renorm_scale_lr:\n",
    "#    for i, param_group in enumerate(ipllr.optimizer.param_groups):\n",
    "#        if i == 0:\n",
    "#            param_group['lr'] = param_group['lr'] * (ipllr.d + 1)\n",
    "#    ipllr.scheduler.warm_lrs[0] = ipllr.scheduler.warm_lrs[0] * (ipllr.d + 1)\n",
    "    \n",
    "for ipllr in ipllrs_calib_renorm_scale_lr:\n",
    "    ipllr.scheduler.warm_lrs[0] = ipllr.scheduler.warm_lrs[0] * (ipllr.d + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = dict()\n",
    "\n",
    "# without calibration\n",
    "#results['ipllr'] = [collect_training_losses(ipllrs[i], batches, n_steps, normalize_first=False) \n",
    "#                    for i in range(N_TRIALS)]\n",
    "\n",
    "#results['ipllr_renorm'] = [collect_training_losses(ipllrs_renorm[i], batches, n_steps, normalize_first=True)\n",
    "#                           for i in range(N_TRIALS)]\n",
    "\n",
    "#results['ipllr_renorm_scale_lr'] = [collect_training_losses(ipllrs_renorm_scale_lr[i], batches, n_steps, \n",
    "#                                                            normalize_first=True) \n",
    "#                                    for i in range(N_TRIALS)]\n",
    "\n",
    "# with calibration\n",
    "results['ipllr_calib'] = [collect_training_losses(ipllrs_calib[i], batches, n_steps, normalize_first=False)\n",
    "                                 for i in range(N_TRIALS)]\n",
    "\n",
    "results['ipllr_calib_renorm'] = [collect_training_losses(ipllrs_calib_renorm[i], batches, n_steps, \n",
    "                                                         normalize_first=True)\n",
    "                                 for i in range(N_TRIALS)]\n",
    "\n",
    "results['ipllr_calib_renorm_scale_lr'] = \\\n",
    "    [collect_training_losses(ipllrs_calib_renorm_scale_lr[i], batches, n_steps, normalize_first=True) \n",
    "     for i in range(N_TRIALS)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'training'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = dict()\n",
    "for key, res in results.items():\n",
    "    losses[key] = [r[0] for r in res]\n",
    "    \n",
    "chis = dict()\n",
    "for key, res in results.items():\n",
    "    chis[key] = [r[1] for r in res]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Losses and derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'loss'\n",
    "plt.figure(figsize=(12, 8))\n",
    "plot_losses_models(losses, key=key, L=L, width=width, lr=base_lr, batch_size=batch_size, mode=mode, \n",
    "                   normalize_first=renorm_first, marker=None, name='IPLLR')\n",
    "plt.savefig(\n",
    "    os.path.join(FIGURES_DIR, 'IPLLRs_1_last_{}_{}_L={}_m={}_lr={}_bs={}.png'.\\\n",
    "                 format(mode, key, L, width, base_lr, batch_size, renorm_first, scale_first_lr)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'chi'\n",
    "plt.figure(figsize=(12, 8))\n",
    "plot_losses_models(chis, key=key, L=L, width=width, lr=base_lr, batch_size=batch_size, mode=mode, marker=None,\n",
    "                   name='IPLLR')\n",
    "plt.savefig(os.path.join(FIGURES_DIR, 'IPLLRs_1_last_{}_{}_L={}_m={}_lr={}_bs={}.png'.\\\n",
    "                         format(mode, key, L, width, base_lr, batch_size)))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
