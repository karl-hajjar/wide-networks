{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "\n",
    "NOTEBOOK_DIR = os.path.dirname(cwd)\n",
    "ROOT = os.path.dirname(os.path.dirname(os.path.dirname(NOTEBOOK_DIR)))\n",
    "\n",
    "FIGURES_DIR = os.path.join(ROOT, 'figures/abc_parameterizations/debug_ipllr_renorm')\n",
    "CONFIG_PATH = os.path.join(ROOT, 'pytorch/configs/abc_parameterizations', 'fc_ipllr_mnist.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, Subset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from utils.tools import read_yaml, set_random_seeds\n",
    "from pytorch.configs.base import BaseConfig\n",
    "from pytorch.configs.model import ModelConfig\n",
    "from pytorch.models.abc_params.fully_connected.ipllr import FcIPLLR\n",
    "from pytorch.models.abc_params.fully_connected.muP import FCmuP\n",
    "from pytorch.models.abc_params.fully_connected.ntk import FCNTK\n",
    "from pytorch.models.abc_params.fully_connected.standard_fc_ip import StandardFCIP\n",
    "from utils.data.mnist import load_data\n",
    "from utils.abc_params.debug_ipllr import *\n",
    "from utils.plot.abc_parameterizations.debug_ipllr import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load basic configuration and define variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRIALS = 5\n",
    "SEED = 30\n",
    "L = 6\n",
    "width = 1024\n",
    "n_warmup_steps = 1\n",
    "batch_size = 512\n",
    "base_lr = 0.1\n",
    "n_steps = 50\n",
    "\n",
    "set_random_seeds(SEED)  # set random seed for reproducibility\n",
    "config_dict = read_yaml(CONFIG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict = read_yaml(CONFIG_PATH)\n",
    "\n",
    "input_size = config_dict['architecture']['input_size']\n",
    "\n",
    "config_dict['architecture']['width'] = width\n",
    "config_dict['architecture']['n_layers'] = L + 1\n",
    "config_dict['optimizer']['params']['lr'] = base_lr\n",
    "config_dict['scheduler'] = {'name': 'warmup_switch',\n",
    "                            'params': {'n_warmup_steps': n_warmup_steps,\n",
    "                                       'calibrate_base_lr': True,\n",
    "                                       'default_calibration': False}}\n",
    "        \n",
    "base_model_config = ModelConfig(config_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data & define models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset, test_dataset = load_data(download=False, flatten=True)\n",
    "train_data_loader = DataLoader(training_dataset, shuffle=True, batch_size=batch_size)\n",
    "test_batches = list(DataLoader(test_dataset, shuffle=False, batch_size=batch_size))\n",
    "batches = list(train_data_loader)\n",
    "eval_batch = test_batches[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial base lr : [69.26097106933594, 36.901771545410156, 60.06058120727539, 61.465023040771484, 69.81842803955078, 80.47272491455078, 242.21490478515625]\n",
      "initial base lr : [68.2101821899414, 38.062652587890625, 67.09164428710938, 72.38660430908203, 78.3447494506836, 93.293212890625, 289.7236633300781]\n",
      "initial base lr : [69.08634948730469, 38.01998519897461, 66.5303726196289, 69.7338638305664, 72.82850646972656, 86.75313568115234, 247.78399658203125]\n",
      "initial base lr : [69.98839569091797, 38.506282806396484, 67.24036407470703, 63.19353485107422, 76.40673065185547, 94.85008239746094, 269.35626220703125]\n",
      "initial base lr : [68.72810363769531, 36.14960479736328, 60.415069580078125, 66.5676498413086, 64.38241577148438, 73.41007995605469, 205.81072998046875]\n"
     ]
    }
   ],
   "source": [
    "ipllrs = [FcIPLLR(base_model_config, n_warmup_steps=12, lr_calibration_batches=batches) for _ in range(N_TRIALS)]\n",
    "base_model_config.scheduler = None\n",
    "muPs = [FCmuP(base_model_config) for _ in range(N_TRIALS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial base lr : [69.26097106933594, 36.901771545410156, 60.06058120727539, 61.465023040771484, 69.81842803955078, 80.47272491455078, 242.21490478515625]\n",
      "initial base lr : [68.2101821899414, 38.062652587890625, 67.09164428710938, 72.38660430908203, 78.3447494506836, 93.293212890625, 289.7236633300781]\n",
      "initial base lr : [69.08634948730469, 38.01998519897461, 66.5303726196289, 69.7338638305664, 72.82850646972656, 86.75313568115234, 247.78399658203125]\n",
      "initial base lr : [69.98839569091797, 38.506282806396484, 67.24036407470703, 63.19353485107422, 76.40673065185547, 94.85008239746094, 269.35626220703125]\n",
      "initial base lr : [68.72810363769531, 36.14960479736328, 60.415069580078125, 66.5676498413086, 64.38241577148438, 73.41007995605469, 205.81072998046875]\n"
     ]
    }
   ],
   "source": [
    "for ipllr in ipllrs:\n",
    "    ipllr.scheduler.calibrate_base_lr(ipllr, batches=batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, ipllr in enumerate(ipllrs):\n",
    "    ipllr.copy_initial_params_from_model(muPs[i])\n",
    "    ipllr.initialize_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input abs mean in training:  0.6950533986091614\n",
      "loss derivatives for model: tensor([[-0.9000,  0.1000,  0.1000,  ...,  0.1000,  0.1000,  0.1000],\n",
      "        [ 0.1000, -0.9000,  0.1000,  ...,  0.1000,  0.1000,  0.1000],\n",
      "        [ 0.1000,  0.1000,  0.1000,  ...,  0.1000,  0.1000, -0.9000],\n",
      "        ...,\n",
      "        [ 0.1000,  0.1000,  0.1000,  ...,  0.1000,  0.1000, -0.9000],\n",
      "        [ 0.1000,  0.1000,  0.1000,  ...,  0.1000,  0.1000,  0.1000],\n",
      "        [ 0.1000,  0.1000,  0.1000,  ...,  0.1000, -0.9000,  0.1000]])\n",
      "average training loss for model1 : 2.3025991916656494\n",
      "\n",
      "input abs mean in training:  0.6950533986091614\n",
      "loss derivatives for model: tensor([[-0.9620,  0.2115,  0.0943,  ...,  0.0697,  0.1970,  0.1129],\n",
      "        [ 0.0280, -0.7540,  0.0885,  ...,  0.0603,  0.2249,  0.1112],\n",
      "        [ 0.0367,  0.2152,  0.0937,  ...,  0.0686,  0.2002, -0.8871],\n",
      "        ...,\n",
      "        [ 0.0421,  0.1994,  0.0960,  ...,  0.0730,  0.1871, -0.8870],\n",
      "        [ 0.0423,  0.1990,  0.0960,  ...,  0.0731,  0.1868,  0.1130],\n",
      "        [ 0.0272,  0.2491,  0.0879,  ...,  0.0595, -0.7725,  0.1109]])\n",
      "average training loss for model1 : 2.347393035888672\n",
      "\n",
      "input abs mean in training:  0.6950533986091614\n",
      "loss derivatives for model: tensor([[-0.9478,  0.1705,  0.0997,  ...,  0.0807,  0.1658,  0.1139],\n",
      "        [ 0.0405, -0.8017,  0.0965,  ...,  0.0726,  0.1911,  0.1154],\n",
      "        [ 0.0500,  0.1751,  0.0992,  ...,  0.0793,  0.1701, -0.8857],\n",
      "        ...,\n",
      "        [ 0.0555,  0.1636,  0.1002,  ...,  0.0826,  0.1596, -0.8868],\n",
      "        [ 0.0558,  0.1631,  0.1003,  ...,  0.0828,  0.1592,  0.1132],\n",
      "        [ 0.0414,  0.1959,  0.0968,  ...,  0.0733, -0.8110,  0.1154]])\n",
      "average training loss for model1 : 2.301145315170288\n",
      "\n",
      "input abs mean in training:  0.6950533986091614\n",
      "loss derivatives for model: tensor([[-0.9420,  0.1577,  0.1009,  ...,  0.0843,  0.1549,  0.1132],\n",
      "        [ 0.0453, -0.8156,  0.0985,  ...,  0.0765,  0.1797,  0.1157],\n",
      "        [ 0.0553,  0.1629,  0.1005,  ...,  0.0827,  0.1598, -0.8862],\n",
      "        ...,\n",
      "        [ 0.0608,  0.1526,  0.1012,  ...,  0.0857,  0.1501, -0.8875],\n",
      "        [ 0.0612,  0.1520,  0.1012,  ...,  0.0859,  0.1495,  0.1124],\n",
      "        [ 0.0473,  0.1797,  0.0990,  ...,  0.0779, -0.8246,  0.1154]])\n",
      "average training loss for model1 : 2.2896902561187744\n",
      "\n",
      "input abs mean in training:  0.6950533986091614\n",
      "loss derivatives for model: tensor([[-0.9385,  0.1511,  0.1013,  ...,  0.0862,  0.1486,  0.1125],\n",
      "        [ 0.0479, -0.8220,  0.0993,  ...,  0.0784,  0.1737,  0.1157],\n",
      "        [ 0.0583,  0.1568,  0.1010,  ...,  0.0846,  0.1540, -0.8866],\n",
      "        ...,\n",
      "        [ 0.0639,  0.1470,  0.1015,  ...,  0.0874,  0.1447, -0.8882],\n",
      "        [ 0.0644,  0.1462,  0.1015,  ...,  0.0876,  0.1440,  0.1117],\n",
      "        [ 0.0508,  0.1717,  0.0999,  ...,  0.0802, -0.8321,  0.1151]])\n",
      "average training loss for model1 : 2.283850908279419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "muPs_0 = [deepcopy(muP) for muP in muPs]\n",
    "\n",
    "x, y = batches[0]\n",
    "for muP in muPs:\n",
    "    train_model_one_step(ipllr, x, y, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input abs mean in training:  0.6950533986091614\n",
      "loss derivatives for model: tensor([[-0.9000,  0.1000,  0.1000,  ...,  0.1000,  0.1000,  0.1000],\n",
      "        [ 0.1000, -0.9000,  0.1000,  ...,  0.1000,  0.1000,  0.1000],\n",
      "        [ 0.1000,  0.1000,  0.1000,  ...,  0.1000,  0.1000, -0.9000],\n",
      "        ...,\n",
      "        [ 0.1000,  0.1000,  0.1000,  ...,  0.1000,  0.1000, -0.9000],\n",
      "        [ 0.1000,  0.1000,  0.1000,  ...,  0.1000,  0.1000,  0.1000],\n",
      "        [ 0.1000,  0.1000,  0.1000,  ...,  0.1000, -0.9000,  0.1000]])\n",
      "average training loss for model1 : 2.3025991916656494\n",
      "\n",
      "input abs mean in training:  0.6950533986091614\n",
      "loss derivatives for model: tensor([[-0.9000,  0.1000,  0.1000,  ...,  0.1000,  0.1000,  0.1000],\n",
      "        [ 0.1000, -0.9000,  0.1000,  ...,  0.1000,  0.1000,  0.1000],\n",
      "        [ 0.1000,  0.1000,  0.1000,  ...,  0.1000,  0.1000, -0.9000],\n",
      "        ...,\n",
      "        [ 0.1000,  0.1000,  0.1000,  ...,  0.1000,  0.1000, -0.9000],\n",
      "        [ 0.1000,  0.1000,  0.1000,  ...,  0.1000,  0.1000,  0.1000],\n",
      "        [ 0.1000,  0.1000,  0.1000,  ...,  0.1000, -0.9000,  0.1000]])\n",
      "average training loss for model1 : 2.3025991916656494\n",
      "\n",
      "input abs mean in training:  0.6950533986091614\n",
      "loss derivatives for model: tensor([[-0.9000,  0.1000,  0.1000,  ...,  0.1000,  0.1000,  0.1000],\n",
      "        [ 0.1000, -0.9000,  0.1000,  ...,  0.1000,  0.1000,  0.1000],\n",
      "        [ 0.1000,  0.1000,  0.1000,  ...,  0.1000,  0.1000, -0.9000],\n",
      "        ...,\n",
      "        [ 0.1000,  0.1000,  0.1000,  ...,  0.1000,  0.1000, -0.9000],\n",
      "        [ 0.1000,  0.1000,  0.1000,  ...,  0.1000,  0.1000,  0.1000],\n",
      "        [ 0.1000,  0.1000,  0.1000,  ...,  0.1000, -0.9000,  0.1000]])\n",
      "average training loss for model1 : 2.3025991916656494\n",
      "\n",
      "input abs mean in training:  0.6950533986091614\n",
      "loss derivatives for model: tensor([[-0.9000,  0.1000,  0.1000,  ...,  0.1000,  0.1000,  0.1000],\n",
      "        [ 0.1000, -0.9000,  0.1000,  ...,  0.1000,  0.1000,  0.1000],\n",
      "        [ 0.1000,  0.1000,  0.1000,  ...,  0.1000,  0.1000, -0.9000],\n",
      "        ...,\n",
      "        [ 0.1000,  0.1000,  0.1000,  ...,  0.1000,  0.1000, -0.9000],\n",
      "        [ 0.1000,  0.1000,  0.1000,  ...,  0.1000,  0.1000,  0.1000],\n",
      "        [ 0.1000,  0.1000,  0.1000,  ...,  0.1000, -0.9000,  0.1000]])\n",
      "average training loss for model1 : 2.3025991916656494\n",
      "\n",
      "input abs mean in training:  0.6950533986091614\n",
      "loss derivatives for model: tensor([[-0.9361,  0.1470,  0.1016,  ...,  0.0874,  0.1445,  0.1119],\n",
      "        [ 0.0495, -0.8253,  0.0997,  ...,  0.0795,  0.1701,  0.1155],\n",
      "        [ 0.0603,  0.1533,  0.1013,  ...,  0.0856,  0.1504, -0.8871],\n",
      "        ...,\n",
      "        [ 0.0660,  0.1436,  0.1017,  ...,  0.0884,  0.1413, -0.8887],\n",
      "        [ 0.0666,  0.1426,  0.1017,  ...,  0.0887,  0.1404,  0.1111],\n",
      "        [ 0.0530,  0.1671,  0.1004,  ...,  0.0817, -0.8368,  0.1148]])\n",
      "average training loss for model1 : 2.279996156692505\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x, y = batches[0]\n",
    "ipllrs_1 = []\n",
    "for ipllr in ipllrs:\n",
    "    train_model_one_step(ipllr, x, y, batch_size)\n",
    "    ipllrs_1.append(deepcopy(ipllr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {'muP': [], 'IPLLR': []}\n",
    "results['muP'] = [collect_scales(muPs[i], muPs_0[i], batches[1:], eval_batch, n_steps) \n",
    "                  for i in range(N_TRIALS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['IPLLR'] = [collect_scales(ipllrs[i], ipllrs_1[i], batches[1:], eval_batch, n_steps) \n",
    "                    for i in range(N_TRIALS)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'training'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_muP = [r[0] for r in results['muP']]\n",
    "losses_ip = [r[0] for r in results['IPLLR']]\n",
    "\n",
    "chis_muP = [r[1] for r in results['muP']]\n",
    "chis_ip = [r[1] for r in results['IPLLR']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Losses and derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "key = 'loss'\n",
    "plt.figure(figsize=(12, 8))\n",
    "plot_losses(losses_ip, losses_muP, key=key, L=L, width=width, lr=base_lr, batch_size=batch_size, mode=mode)\n",
    "plt.savefig(os.path.join(FIGURES_DIR, '{}_{}_L={}_m={}_lr={}_bs={}.png'.format(mode, key, L, width, base_lr, \n",
    "                                                                               batch_size)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'chi'\n",
    "plt.figure(figsize=(12, 8))\n",
    "plot_losses(chis_ip, chis_muP, key=key, L=L, width=width, lr=base_lr, batch_size=batch_size, mode=mode)\n",
    "plt.savefig(os.path.join(FIGURES_DIR, '{}_{}_L={}_m={}_lr={}_bs={}.png'.format(mode, key, L, width, base_lr, \n",
    "                                                                               batch_size)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Magnitude of the actvations of the network at different layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_muP = [r[2] for r in results['muP']]\n",
    "dfs_ip = [r[2] for r in results['IPLLR']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'h'\n",
    "for l in range(L-1, L+2):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plot_output_scale(dfs_ip, dfs_muP, layer=l, key=key, L=L, width=width, lr=base_lr, batch_size=batch_size, \n",
    "                      mode=mode, y_scale='log')\n",
    "    plt.savefig(os.path.join(FIGURES_DIR, \n",
    "                             '{}_{}_layer_{}_L={}_m={}_lr={}_bs={}.png'.format(mode, key, l, L, width, base_lr, \n",
    "                                                                               batch_size)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'h'\n",
    "for l in range(L-1, L+2):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plot_output_scale(dfs_ip, None, layer=l, key=key, L=L, width=width, lr=base_lr, batch_size=batch_size, \n",
    "                      mode=mode, y_scale='log')\n",
    "    plt.savefig(os.path.join(FIGURES_DIR, \n",
    "                             '{}_{}_ip_layer_{}_L={}_m={}_lr={}_bs={}.png'.format(mode, key, l, L, width, base_lr, \n",
    "                                                                                  batch_size)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contribution of the init to the activations at different layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "key = 'h_init'\n",
    "for l in range(1, L+2):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plot_output_scale(dfs_ip, dfs_muP, layer=l, key=key, L=L, width=width, lr=base_lr, batch_size=batch_size,\n",
    "                      mode=mode, y_scale='log')\n",
    "    plt.savefig(os.path.join(FIGURES_DIR, \n",
    "                             '{}_{}_layer_{}_L={}_m={}_lr={}_bs={}.png'.format(mode, key, l, L, width, base_lr,\n",
    "                                                                               batch_size)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Magnitude of the update at different layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "key = 'delta_h'\n",
    "for l in range(1, L+2):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plot_output_scale(dfs_ip, dfs_muP, layer=l, key=key, L=L, width=width, lr=base_lr, batch_size=batch_size,\n",
    "                      mode=mode, y_scale='log')\n",
    "    plt.savefig(os.path.join(FIGURES_DIR, \n",
    "                             '{}_{}_layer_{}_L={}_m={}_lr={}_bs={}.png'.format(mode, key, l, L, width, base_lr,\n",
    "                                                                               batch_size)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_muP = [r[3] for r in results['muP']]\n",
    "dfs_ip = [r[3] for r in results['IPLLR']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Losses and derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'loss'\n",
    "plt.figure(figsize=(12, 8))\n",
    "plot_losses(losses_ip, losses_muP, key=key, L=L, width=width, lr=base_lr, batch_size=batch_size, mode=mode)\n",
    "plt.savefig(os.path.join(FIGURES_DIR, '{}_{}_L={}_m={}_lr={}_bs={}.png'.format(mode, key, L, width, base_lr, \n",
    "                                                                               batch_size)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'chi'\n",
    "plt.figure(figsize=(12, 8))\n",
    "plot_losses(chis_ip, chis_muP, key=key, L=L, width=width, lr=base_lr, batch_size=batch_size, mode=mode)\n",
    "plt.savefig(os.path.join(FIGURES_DIR, '{}_{}_L={}_m={}_lr={}_bs={}.png'.format(mode, key, L, width, base_lr, \n",
    "                                                                               batch_size)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Magnitude of the actvations of the network at different layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_muP = [r[2] for r in results['muP']]\n",
    "dfs_ip = [r[2] for r in results['IPLLR']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'h'\n",
    "for l in range(L-1, L+2):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plot_output_scale(dfs_ip, dfs_muP, layer=l, key=key, L=L, width=width, lr=base_lr, batch_size=batch_size, \n",
    "                      mode=mode, y_scale='log')\n",
    "    plt.savefig(os.path.join(FIGURES_DIR, \n",
    "                             '{}_{}_layer_{}_L={}_m={}_lr={}_bs={}.png'.format(mode, key, l, L, width, base_lr, \n",
    "                                                                               batch_size)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'h'\n",
    "for l in range(L-1, L+2):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plot_output_scale(dfs_ip, None, layer=l, key=key, L=L, width=width, lr=base_lr, batch_size=batch_size, \n",
    "                      mode=mode, y_scale='log')\n",
    "    plt.savefig(os.path.join(FIGURES_DIR, \n",
    "                             '{}_{}_ip_layer_{}_L={}_m={}_lr={}_bs={}.png'.format(mode, key, l, L, width, base_lr, \n",
    "                                                                                  batch_size)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contribution of the init to the activations at different layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "key = 'h_init'\n",
    "for l in range(1, L+2):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plot_output_scale(dfs_ip, dfs_muP, layer=l, key=key, L=L, width=width, lr=base_lr, batch_size=batch_size,\n",
    "                      mode=mode, y_scale='log')\n",
    "    plt.savefig(os.path.join(FIGURES_DIR, \n",
    "                             '{}_{}_layer_{}_L={}_m={}_lr={}_bs={}.png'.format(mode, key, l, L, width, base_lr,\n",
    "                                                                               batch_size)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Magnitude of the update at different layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "key = 'delta_h'\n",
    "for l in range(1, L+2):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plot_output_scale(dfs_ip, dfs_muP, layer=l, key=key, L=L, width=width, lr=base_lr, batch_size=batch_size,\n",
    "                      mode=mode, y_scale='log')\n",
    "    plt.savefig(os.path.join(FIGURES_DIR, \n",
    "                             '{}_{}_layer_{}_L={}_m={}_lr={}_bs={}.png'.format(mode, key, l, L, width, base_lr,\n",
    "                                                                               batch_size)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
