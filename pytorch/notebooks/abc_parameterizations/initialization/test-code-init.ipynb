{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "\n",
    "NOTEBOOK_DIR = os.path.dirname(cwd)\n",
    "ROOT = os.path.dirname(os.path.dirname(os.path.dirname(NOTEBOOK_DIR)))\n",
    "\n",
    "FIGURES_DIR = os.path.join(ROOT, 'figures/abc_parameterizations/initialization')\n",
    "CONFIG_PATH = os.path.join(ROOT, 'pytorch/configs/abc_parameterizations/fc_abc.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from utils.tools import read_yaml, set_random_seeds\n",
    "from utils.plot.abc_parameterizations.initializations import *\n",
    "from pytorch.configs.model import ModelConfig\n",
    "from pytorch.models.abc_params.fully_connected import ntk, ip, muP, ipllr\n",
    "from pytorch.models.abc_params.fully_connected.standard_fc_ip import StandardFCIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 5\n",
    "bias = False\n",
    "width = 1024\n",
    "SEED = 42\n",
    "\n",
    "set_random_seeds(SEED)  # set random seed for reproducibility\n",
    "config_dict = read_yaml(CONFIG_PATH)\n",
    "\n",
    "config_dict['architecture']['n_layers'] = L + 1\n",
    "base_model_config = ModelConfig(config_dict)\n",
    "base_model_config.architecture['bias'] = bias\n",
    "base_model_config.architecture['width'] = width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ntk.FCNTK(base_model_config)\n",
    "model.init_scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.2514, -1.5190,  0.8979,  ..., -2.1606, -0.3204,  0.0087],\n",
       "        [-0.8779,  0.1613, -0.3990,  ..., -1.4587,  0.9024, -3.3510],\n",
       "        [-0.1970,  0.6471, -1.0071,  ..., -0.0973,  0.2561,  0.0622],\n",
       "        ...,\n",
       "        [-1.9033, -0.0588, -2.1137,  ..., -1.2381, -0.3363, -0.9464],\n",
       "        [ 0.1160, -0.1671,  0.3530,  ..., -1.7505, -1.0413,  1.9345],\n",
       "        [-0.5322, -0.1971, -0.1059,  ..., -0.6193, -2.8023, -0.3825]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input_layer.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-5.5518, grad_fn=<MinBackward1>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input_layer.weight.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.7181, grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input_layer.weight.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 1024])\n",
      "torch.Size([1024, 1024])\n",
      "torch.Size([1024, 1024])\n",
      "torch.Size([1024, 1024])\n"
     ]
    }
   ],
   "source": [
    "for l, layer in enumerate(model.intermediate_layers):\n",
    "    print(layer.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.5464, -2.8679, -2.1360,  ..., -1.4663, -1.5891,  0.6221],\n",
       "        [-1.5016,  1.3141,  0.6846,  ..., -2.2101, -0.6813,  0.1306],\n",
       "        [ 0.8891, -2.7589, -0.5882,  ..., -0.8268,  0.7493,  2.0032],\n",
       "        ...,\n",
       "        [ 0.7670,  1.3615,  0.8179,  ..., -0.1174, -2.4032,  1.4691],\n",
       "        [-0.6120,  2.5579, -2.0396,  ...,  1.5252,  2.1685, -0.5176],\n",
       "        [ 1.5199, -0.4976, -1.2771,  ..., -1.5009,  0.4476,  0.2565]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-6.9049, grad_fn=<MinBackward1>)\n",
      "tensor(7.3323, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print(layer.weight.min())\n",
    "print(layer.weight.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### muP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = muP.FCmuP(base_model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.init_scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0006, -0.0795,  0.0343,  ...,  0.0354,  0.0134, -0.0436],\n",
       "        [ 0.0874, -0.0167,  0.0194,  ..., -0.0643, -0.0449, -0.0027],\n",
       "        [-0.0594,  0.0119,  0.0116,  ...,  0.0064, -0.0837,  0.0390],\n",
       "        ...,\n",
       "        [ 0.0317,  0.0235,  0.0061,  ...,  0.0040,  0.0278,  0.0158],\n",
       "        [ 0.0348, -0.0858,  0.0655,  ..., -0.0564, -0.1332, -0.0009],\n",
       "        [-0.0589, -0.1162,  0.0023,  ...,  0.0028, -0.0088, -0.0072]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input_layer.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.1904, grad_fn=<MinBackward1>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input_layer.weight.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1642, grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input_layer.weight.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 1024])\n",
      "torch.Size([1024, 1024])\n",
      "torch.Size([1024, 1024])\n",
      "torch.Size([1024, 1024])\n"
     ]
    }
   ],
   "source": [
    "for l, layer in enumerate(model.intermediate_layers):\n",
    "    print(layer.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0392, -0.0066, -0.0253,  ..., -0.0693,  0.1090,  0.0372],\n",
       "        [ 0.0506, -0.0527, -0.0031,  ...,  0.0178,  0.0054, -0.0444],\n",
       "        [ 0.0443,  0.0079,  0.0031,  ..., -0.0035,  0.0084, -0.0077],\n",
       "        ...,\n",
       "        [ 0.0633,  0.0477,  0.0267,  ..., -0.0108,  0.0675,  0.0224],\n",
       "        [-0.0389,  0.0447,  0.0604,  ..., -0.0927,  0.0067, -0.0268],\n",
       "        [ 0.0177,  0.0112,  0.0229,  ..., -0.0127,  0.0472, -0.0184]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-6.9049, grad_fn=<MinBackward1>)\n",
      "tensor(7.3323, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print(layer.weight.min())\n",
    "print(layer.weight.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
